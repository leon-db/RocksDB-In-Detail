# 故障恢复

    故障恢复是数据库保留原子性和持久性的基本技术手段（ACID中的A和D）。
在RocksDB中，数据的故障恢复的过程基本调用栈如下：

     1.  DB::Open
     2.  DBImpl::Recover
     3.  VersionSet::Recover

比如我们打印一个程序调用栈如下截图：

   ![Recover调用栈](./images/recover_stack.jpg)

## blob文件存储到version的过程
  对于之前老版本的blobdb kv分离的实现，默认是不track blob文件的。因此该版本的kv分离
  实现在发生故障的时候，没有办法保证数据的可恢复性。

  要做到数据的可恢复性，我们必须在日志中追踪每个根据的变更过程，
  这个机制目前主要是通过VersionEdit来实现。之所有使用这种机制，原理
  类似于Innodb中的 double write buffer。 当我们在做compaction的时候
  我们没有办法来保证文件操作的原子性。故而通过把文件的变动先临时保存在manifest文件中
  当所有的文件操作成功后，我们原子的切换该manifest文件，联动WAL日志，这样可以正确的做到
  原子性。
  
### 一个blob文件添加的全过程
  先看接口
  ```c++
  Status VersionSet::LogAndApply(ColumnFamilyData* column_family_data,
                                 const MutableCFOptions& mutable_cf_options,
                                 const autovector<VersionEdit*>& edit_list,
                                 InstrumentedMutex* mu, Directory* db_directory,
                                 bool new_descriptor_log,
                                 const ColumnFamilyOptions* new_cf_options)
```
  可以看到，我们的版本迭代变更是通过，应用（apply)一个个的VersionEdit来实现的。当然在这个实现的过程中
  可能会考虑效率的原因，使用组提交等相关技术。（类似于WAL写入时候的write_batch合并）
  
  下面我们详细的分析应用一个VersionEdit的过程。
  这个过程在RocksDB的整个实现过程中，非常的重要。从故障恢复（Recovery）,到我们的flush和compaction
  实现，基本上都离不开这个核心流程。


  在详细的介绍这个接口的实现的过程中，我们有必要补充一些基本的知识。如之前描述，Recover、flush和compaction等过程
都要依赖这个操作。我们都知道RocksDB源自LevelDB,只是在LevelDB的基础上添加了Column Family。
这个抽象的好处，大致是：
    1. 对于不同的数据可以做到比较好的隔离
    2. 相同类型的数据放在一个Cf中管理会更加的高效，比如说压缩等
因此在RocksDB的很多接口中都会隐含接口的操作单位为一个个的Column Family. 这个接口也不例外，它的第一个参数
就是写明要对哪个cf进行操作变更。
  
  详细的应用过程如下：
     首先是检查传入的VersionEdit集合 edit_list
  显然，如果我们传入的cfd 参数为空，唯一的可能就是要添加一个cf。因此我们可以看到相关的代码都会对这个进行检查
  ```c++
if (column_family_data == nullptr) {
      assert(num_edits == 1);
      assert(edit_list[0]->is_column_family_add_);
      assert(new_cf_options != nullptr);
  }
```
  对于每个后台线程（flush和compaction）它们总是在执行任务，参考wal组提交机制
我们可以利用类似的思想来提高效率
```c++
   ManifestWriter w(mu, column_family_data, edit_list);
   manifest_writers_.push(&w);
   // 如果不是leader，那么就等待Leader处理完成
   while(!w.done && &w != manifest_writers_.front()) {
     w.cv.Wait();
   }
   if (w.done) {
     return w.status;
   }
   // Leader 执行下面的逻辑
```
   可以看到对于每个线程执行Apply VersionEdit操作，我们首先是把对应的ve都封装到一个
   ManifestWriter任务中去，然后放入到全局的manifest_writers_列表中去，
   如果队列中没有其他的任务，那么当前的任务就是leader, 它会负责ve的写入操作。
   而如果我们的线程是follower，那么这里只需要简单的等待leader完成相应的任务。然后leader会通知follower
   任务完成.
   
为了方便理解，这里要梳理一下基本的数据结构：
   1. manifest_writers_ 是我们写线程要进行写数据的结合
   2. 对于每个写线程，它都通过ve的集合来表示

所以leader线程的处理过程如下：
   ```c++
    ManifestWriter* last_writer = &w;  // leader
    if (w.edit_list.front->IsColumnFamilyManipulation()) {
      LogAndApplyCFHelper(w.edit_list.front());
      batch_edits.push_back(w.edit_list.front());
    } else {
      v = new Version(column_family_data, this, current_version_number++);
      builder_guard.reset(new BaseReferencedVersionBuilder(column_family_data));
      auto* builder = builder_guard->version_builder();
      // 依次遍历每个writer
      for (const auto& writer : manifest_writers_) {
        if (writer->edit_list.front()->IsColumnFamilyManipulation() ||
            writer->cfd->GetID() != column_family_data->GetID()) {
          break;
        }
        // 依次遍历每个write要写入的ve数据
        last_writer = writer;
        for (const auto& edit : writer->edit_list) {
          LogAndApplyHelper(column_family_data, builder, v, edit, mu);
          batch_edits.push_back(edit);
        }
      }
      builder->SaveTo(v->storage_info());
    }
```
   在上面的过程中，我们可以看到我们依次把不同的writer数据聚合到leader来一个个的处理，那么这里有一个问题
不同的任务在执行这些ve操作的时候，执行顺序会影响正确性吗？
   答案是： 不会影响正确性.
首先因为compaction执行的时候，不允许有交集。其实我们后台执行的这些compaction也都是append only的方式来写数据的。
在这个过程中，我们只会把没有快照引用的垃圾数据在compaction的过程中删除， 然后生成新的文件。详细的可以参考我们的快照模块。
   在上面的应用过程中，有一个helper函数，这个函数的主要作用就让对应的builder应用上我们的增量操作
  ```c++
     void VersionSet::LogAndApplyHelper(ColumnFamilyData* cfd,
                                        VersionBuilder* builder, Version* v,
                                        VersionEdit* edit, InstrumentedMutex* mu) {
  //
  if (!edit->has_prev_log_number) {
    edit->SetPrevLogNumber(prev_log_number_);
  }
  edit->SetNextFile(next_file_number_.load());
  edit->SetLastSequence(last_sequence_);
  builder->Apply(edit);
  //
}
```
  这个helper函数的作用非常简单，就是设置一下这个ve的一些上下文，然后把这个ve应用到builder中去
既然都是应用到builder中去，通过上面的代码片段，我们可以看到， 这个builder其实也是通过对应的cf来初始化的
然后通过cf来获取对应的cf buidler，然后拿着当前cf的最新的version来应用一个个的ve.

为了方便理解，我这里把重要的逻辑通过下面的伪代码来再次描述一遍：
```c++
   // 1. 通过cfd,来初始化一个版本，引用cfd的最新版本的数据
   v = new Version(column_family_data, this, current_version_number_++);
   builder_guard.reset(new BaseReferencedVersionBuilder(column_family_data));
   auto* builder = builder_guard->version_builder();
   // 2. 把所有其他线程的write都一一聚合到对应的buider中
   for (const auto& edit : writer->edit_list) {
     LogAndApplyHelper(column_family_data, builder, v, edit, mu);
   }
   // 3. 把缓存在builder中的所有的ve，一个个的保存到当前的version中去
   // 如函数名称那样，是把builder中保存的一个个的添加到现有的version中去
   builder->SaveTo(v->storage_info());
```

#### 如何把缓存的ve数据一个个的添加到现有的版本中去的
   如之前的分析，所有的新增的ve都保存在builder中，显然就下面的rep_中
  ```c++
void VersionBuilder::SaveTo(VersionStorageInfo* vstorage, Status* status) {
  rep_->SaveTo(vstorage, status);
}
```
   那么这个rep_内部对象，有啥重要的数据结构呢？

  1. base_vstorage_  这个对象就是指向builder刚刚创建时的cfd的最新的version
  
在这个方法中还有一个VersionStorageInfo* 对象，要深入的理解，必须明白这个vstorage和Rep中的base_storage_对象有啥区别
。通过上面的代码调用我们知道，传入的vstorage对象是当前cfd对应的最新的verison中存储的数据。

在install之前，第一件事情，就是校验LSM数据的一致性. 校验数据的一致性，这块主要是在kv分离的模块中添加的，
在之前的版本中，是没有这一步的。
   因为我们要跟踪blob文件和sst之前的关联，所以定义数据结构
```c++
  using ExpectedLinkedSsts =
     std::unordered_map<uint64_t, BlobFileMetaData::LinkedSsts>;
     
  // 对于LinkedSsts定义如下
  using LinkedSsts = std::unordered_set<uint64_t>;
```
  我们就是通过ExpectedLinkedSsts这个结构来追踪一个blob文件跟多少个sst文件相互关联. 显然
一个sst中的key可能会关联不同的blob文件，同样一个blob文件中的value，可能来自不同sst的引用。

  在这个检查的过程中，基本的逻辑就是，扫描LSM树的每一层的每一个文件，然后根据每个sst中记录
的 oldest_blob_file_number，来和对应的sst建立一个多对多的关系。
  这里有一个问题要注意一下，如果一个sst中的key引用了多个blob文件，我们也只会记录最后的那个文件。
比如说：一个sst文件引用了blob1和blob2文件，那么我们的sst中只会记录blob1。
这里假设blob1的文件号小于blob2的文件号。
   这个检查的过程主要分两个level, level0和非level0，主要是检查文件的重叠情况是否满足要求。
检查完这些基本信息和更新blob文件及sst文件的关联信息之后。开始检查blob文件的正确性

```c++
    // Make sure that all blob files in the version have non-garbage data.
    const auto& blob_files = vstorage->GetBlobFiles();
    for (const auto& pair : blob_files) {
      const uint64_t blob_file_number = pair.first;
      const auto& blob_file_meta = pair.second;
      assert(blob_file_meta);

      if (blob_file_meta->GetGarbageBlobCount() >=
        blob_file_meta->GetTotalBlobCount()) {
        std::ostringstream oss;
        oss << "Blob file #" << blob_file_number
          << " consists entirely of garbage";

         return Status::Corruption("VersionBuilder", oss.str());
      }

      if (blob_file_meta->GetLinkedSsts() !=
          expected_linked_ssts[blob_file_number]) {
        std::ostringstream oss;
        oss << "Links are inconsistent between table files and blob file #"
            << blob_file_number;

        return Status::Corruption("VersionBuilder", oss.str());
      }
    }
```
   把所有的active的blob文件提取出来，然后依次遍历blob文件, key是blob的文件号，value是blob的meta信息
如果取出的blob文件的删除的KV对比blob本身记录的meta的KV对还要多的话，那么这种情况下，我们应该认为这个blob文件应该是
inactive的，并且要被purge线程删除。而不是出现在active的blob文件列表中。同时，如果我们从blob的元信息中获取的
sst链接信息和扫描时候的不匹配，那么认为数据库关于blob这一块有数据一致性的问题。


#### 添加文件到当前的版本中
   文件的添加，是如何反应在版本的变化中的？

我们都知道，compaction或者flush都会引发文件的变化，而这些文件的变化是要使用版本来控制的。那么他们之间的关系时怎样的呢？
如果这个时候把新文件，添加到老版本中，那岂不是会让其他的线程看到不该看到的数据？
   其实我们之前的代码已经解释了这个问题，首先在新版本install之前，其他的线程是看不到这个版本数据的变化的。
我们在生成新版本的时候，第一步就是拷贝老版本的数据，形成一个新的VersionStoreInfo对象，这个对象只属于新的Version。
而目前新的Version因为还没有install到对应的cf中，所以其他的读也是看不到我们新的文件的。
   这里有个疑问就是，如果不同的版本总是拷贝文件，那么性能岂不是会很差？其实不然，RocksDB对这些都做了特殊的处理
详细的代码如下：
 
```c++
    TODO
```
   到此，我们基本上把数据迁移的正确性和性能都解释完成，那么从high level层面来看，整个过程就是：

1. 创建一个新的version
2. 新的version拷贝老的version的所有active文件
3. 我们把builder中临时保存的ve文件，添加到新版本中
4. 更新cf的最新的current的version为我们刚刚创建的那个version

从上面的过程中，我们可以看到正确性，包括mvcc和快照机制的联合都是正确的。

宏观上我们已经分析大致的过程，那么现在就让我们来看看详细的细节吧

```c++
  for (int level = 0; level < base_vstorage_->num_levels(); level++) {
     const auto& cmp = (level == 0) ? level_zero_cmp_ : level_nonzero_cmp_;
     const auto& base_files = base_vstorage_->LevelFiles(level);
     auto base_iter = base_files.begin();
     auto base_end = base_files.end();
     const auto& unordered_added_files = levels_[level].added_files;
     vstorage->Reserve(level,
         base_files.size() + unordered_added_files.size());

     // Sort added files for the level.
     std::vector<FileMetaData*> added_files;
     added_files.reserve(unordered_added_files.size());
     for (const auto& pair : unordered_added_files) {
       added_files.push_back(pair.second);
     }
     std::sort(added_files.begin(), added_files.end(), cmp);

    // Add all smaller files listed in base_
    for (auto bpos = std::upper_bound(base_iter, base_end, added, cmp);
         base_iter != bpos; ++base_iter) {
      MaybeAddFile(vstorage, level, *base_iter);
    }
    MaybeAddFile(vstorage, level, added);
  }

      // Add remaining base files
     for (; base_iter != base_end; ++base_iter) {
        MaybeAddFile(vstorage, level, *base_iter);
     }
    }

    SaveBlobFilesTo(vstorage);

    s = CheckConsistency(vstorage);
  }
}
```
  整体上就是把base_vstoreage_中的数据加上新增的数据merge到一个新版本中vstorage。
在添加文件的过程中，会调用MaybeAddFile (todo 梳理这个函数)
   这个函数的大致意思是：这个过程中要添加的文件，可能会出现在删除文件列表中。因为需要再一下的
确认。
  如果确实要添加该文件，那么会在vstorage中添加，如果要删除就remove对于的文件。
 

